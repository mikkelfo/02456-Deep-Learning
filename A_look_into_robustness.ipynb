{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A look into robustness of CNNs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZxi0VB9RUOJ"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ronh-tcCxWkZ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.nn.parameter import Parameter\n",
        "from torchvision.datasets import MNIST\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "\n",
        "from torch.nn.parameter import Parameter\n",
        "from torchvision.datasets import MNIST\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM_5vYkkW3bo"
      },
      "source": [
        "def train(model, train_loader, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, data in enumerate(train_loader):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 1000 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(inputs), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    total, correct = 0, 0\n",
        "\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(Variable(images))\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum()\n",
        "    \n",
        "    print('Accuracy of the network on the {} test images: {:4.2f} %'.format(\n",
        "    len(test_loader.dataset), 100 * correct.true_divide(total)))\n",
        "\n",
        "train_kwargs = {'batch_size': 64}\n",
        "test_kwargs = {'batch_size': 64}\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaAGfi9nxcs3"
      },
      "source": [
        "# A look into robustness - 02456 Deep Learning project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzWG-TzPymOb"
      },
      "source": [
        "## Create a high-accuracy network for the MNIST dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmFyjeZEW3Ze"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv32_1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
        "        self.conv32_2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
        "        self.BN32_1 = nn.BatchNorm2d(32)\n",
        "        self.BN32_2 = nn.BatchNorm2d(32)\n",
        "        self.BN32_3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=5, stride=2, padding=2)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "        self.conv64_1 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "        self.conv64_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
        "        self.BN64_1 = nn.BatchNorm2d(64)\n",
        "        self.BN64_2 = nn.BatchNorm2d(64)\n",
        "        self.BN64_3 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv128 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4)\n",
        "        self.BN128 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.fc = nn.Linear(1*1*128, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):                          # (28, 28, 1)\n",
        "        x = self.BN32_1(F.relu(self.conv32_1(x)))    # (26, 26, 32)\n",
        "        x = self.BN32_2(F.relu(self.conv32_2(x)))    # (24, 24, 32)\n",
        "        x = self.BN32_3(F.relu(self.pool(x)))        # (12, 12, 32)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.BN64_1(F.relu(self.conv64_1(x)))    # (10, 10, 64)\n",
        "        x = self.BN64_2(F.relu(self.conv64_2(x)))    # (8, 8, 64)\n",
        "        x = self.BN64_3(F.relu(self.pool(x)))        # (4, 4, 64)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.BN128(F.relu(self.conv128(x)))     # (1, 1, 128)\n",
        "        # Flatten\n",
        "        x = x.view(-1, 1*1*128)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = F.softmax(self.fc(x))\n",
        "\n",
        "        return x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0TlLug6W3eX"
      },
      "source": [
        "# Training settings\n",
        "\n",
        "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transform)\n",
        "dataset2 = datasets.MNIST('../data', train=False,\n",
        "                    transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-OZ79QC5FOi",
        "outputId": "3524a0f7-2c4f-4330-abb7-113fec85c415"
      },
      "source": [
        "model = Net().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
        "for epoch in range(1, 20 + 1):\n",
        "    train(model, train_loader, optimizer, criterion, epoch)\n",
        "    test(model, test_loader)\n",
        "    scheduler.step()\n",
        "\n",
        "torch.save(model.state_dict(), \"mnist_cnn.pt\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.311024\n",
            "Accuracy of the network on the 10000 test images: 98.77 %\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.476732\n",
            "Accuracy of the network on the 10000 test images: 99.23 %\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.472849\n",
            "Accuracy of the network on the 10000 test images: 99.24 %\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.461550\n",
            "Accuracy of the network on the 10000 test images: 99.40 %\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.476785\n",
            "Accuracy of the network on the 10000 test images: 99.36 %\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 1.461397\n",
            "Accuracy of the network on the 10000 test images: 99.53 %\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 1.461316\n",
            "Accuracy of the network on the 10000 test images: 99.52 %\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 1.461202\n",
            "Accuracy of the network on the 10000 test images: 99.51 %\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 1.461267\n",
            "Accuracy of the network on the 10000 test images: 99.55 %\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 1.461184\n",
            "Accuracy of the network on the 10000 test images: 99.52 %\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 1.461164\n",
            "Accuracy of the network on the 10000 test images: 99.53 %\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 1.461172\n",
            "Accuracy of the network on the 10000 test images: 99.52 %\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 1.461319\n",
            "Accuracy of the network on the 10000 test images: 99.49 %\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 1.461225\n",
            "Accuracy of the network on the 10000 test images: 99.51 %\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 1.461259\n",
            "Accuracy of the network on the 10000 test images: 99.50 %\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 1.461264\n",
            "Accuracy of the network on the 10000 test images: 99.52 %\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 1.462022\n",
            "Accuracy of the network on the 10000 test images: 99.53 %\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 1.461182\n",
            "Accuracy of the network on the 10000 test images: 99.54 %\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 1.461159\n",
            "Accuracy of the network on the 10000 test images: 99.54 %\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 1.461189\n",
            "Accuracy of the network on the 10000 test images: 99.51 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUjVi5yXTu-W"
      },
      "source": [
        "# Networks definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDNDkJOVUK_5"
      },
      "source": [
        "#### Original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aqz6UegPUK_6"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv32_1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
        "        self.conv32_2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
        "        self.BN32_1 = nn.BatchNorm2d(32)\n",
        "        self.BN32_2 = nn.BatchNorm2d(32)\n",
        "        self.BN32_3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=5, stride=2, padding=2)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "        self.conv64_1 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "        self.conv64_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
        "        self.BN64_1 = nn.BatchNorm2d(64)\n",
        "        self.BN64_2 = nn.BatchNorm2d(64)\n",
        "        self.BN64_3 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv128 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4)\n",
        "        self.BN128 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.fc = nn.Linear(1*1*128, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):                          # (28, 28, 1)\n",
        "        x = self.BN32_1(F.relu(self.conv32_1(x)))    # (26, 26, 32)\n",
        "        x = self.BN32_2(F.relu(self.conv32_2(x)))    # (24, 24, 32)\n",
        "        x = self.BN32_3(F.relu(self.pool(x)))        # (12, 12, 32)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.BN64_1(F.relu(self.conv64_1(x)))    # (10, 10, 64)\n",
        "        x = self.BN64_2(F.relu(self.conv64_2(x)))    # (8, 8, 64)\n",
        "        x = self.BN64_3(F.relu(self.pool(x)))        # (4, 4, 64)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.BN128(F.relu(self.conv128(x)))     # (1, 1, 128)\n",
        "        # Flatten\n",
        "        x = x.view(-1, 1*1*128)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = F.softmax(self.fc(x))\n",
        "\n",
        "        return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0RcukT8UK_6"
      },
      "source": [
        "#### Avg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qyby5O4KUK_6"
      },
      "source": [
        "class Net_avg(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_avg, self).__init__()\n",
        "\n",
        "        self.conv32_1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
        "        self.conv32_2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
        "        self.BN32_1 = nn.BatchNorm2d(32)\n",
        "        self.BN32_2 = nn.BatchNorm2d(32)\n",
        "        self.BN32_3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.pool = nn.AvgPool2d(kernel_size=5, stride=2, padding=2)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "        self.conv64_1 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "        self.conv64_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
        "        self.BN64_1 = nn.BatchNorm2d(64)\n",
        "        self.BN64_2 = nn.BatchNorm2d(64)\n",
        "        self.BN64_3 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv128 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4)\n",
        "        self.BN128 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.fc = nn.Linear(1*1*128, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):                          # (28, 28, 1)\n",
        "        x = self.BN32_1(F.relu(self.conv32_1(x)))    # (26, 26, 32)\n",
        "        x = self.BN32_2(F.relu(self.conv32_2(x)))    # (24, 24, 32)\n",
        "        x = self.BN32_3(F.relu(self.pool(x)))        # (12, 12, 32)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.BN64_1(F.relu(self.conv64_1(x)))    # (10, 10, 64)\n",
        "        x = self.BN64_2(F.relu(self.conv64_2(x)))    # (8, 8, 64)\n",
        "        x = self.BN64_3(F.relu(self.pool(x)))        # (4, 4, 64)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.BN128(F.relu(self.conv128(x)))     # (1, 1, 128)\n",
        "        # Flatten\n",
        "        x = x.view(-1, 1*1*128)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = F.softmax(self.fc(x))\n",
        "\n",
        "        return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV9SvI35UK_7"
      },
      "source": [
        "#### BatchNorm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2b1ZaimUK_7"
      },
      "source": [
        "class Net_BN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_BN, self).__init__()\n",
        "\n",
        "        self.conv32_1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
        "        self.conv32_2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
        "        self.BN32_1 = nn.BatchNorm2d(32)\n",
        "        self.BN32_2 = nn.BatchNorm2d(32)\n",
        "        self.BN32_3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=5, stride=2, padding=2)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "        self.conv64_1 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "        self.conv64_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
        "        self.BN64_1 = nn.BatchNorm2d(64)\n",
        "        self.BN64_2 = nn.BatchNorm2d(64)\n",
        "        self.BN64_3 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv128 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4)\n",
        "        self.BN128 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.fc = nn.Linear(1*1*128, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):                          # (28, 28, 1)\n",
        "        x = (F.relu(self.conv32_1(x)))    # (26, 26, 32)\n",
        "        x = (F.relu(self.conv32_2(x)))    # (24, 24, 32)\n",
        "        x = (F.relu(self.pool(x)))        # (12, 12, 32)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = (F.relu(self.conv64_1(x)))    # (10, 10, 64)\n",
        "        x = (F.relu(self.conv64_2(x)))    # (8, 8, 64)\n",
        "        x = (F.relu(self.pool(x)))        # (4, 4, 64)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = (F.relu(self.conv128(x)))     # (1, 1, 128)\n",
        "        # Flatten\n",
        "        x = x.view(-1, 1*1*128)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = F.softmax(self.fc(x))\n",
        "\n",
        "        return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbM7eZr_UK_8"
      },
      "source": [
        "#### Conv Pool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxePCUboUK_8"
      },
      "source": [
        "class Net_ConvPool(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_ConvPool, self).__init__()\n",
        "\n",
        "        self.conv32_1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
        "        self.conv32_2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
        "        self.BN32_1 = nn.BatchNorm2d(32)\n",
        "        self.BN32_2 = nn.BatchNorm2d(32)\n",
        "        self.BN32_3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        # self.pool = nn.AvgPool2d(kernel_size=5, stride=2, padding=2)\n",
        "\n",
        "        self.pool_1 = nn.Conv2d(in_channels=32, out_channels=32, stride=2, kernel_size=5, padding=2)\n",
        "        self.pool_2 = nn.Conv2d(in_channels=64, out_channels=64, stride=2, kernel_size=5, padding=2)\n",
        "\n",
        "\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "        self.conv64_1 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "        self.conv64_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
        "        self.BN64_1 = nn.BatchNorm2d(64)\n",
        "        self.BN64_2 = nn.BatchNorm2d(64)\n",
        "        self.BN64_3 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv128 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4)\n",
        "        self.BN128 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.fc = nn.Linear(1*1*128, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):                          # (28, 28, 1)\n",
        "        x = self.BN32_1(F.relu(self.conv32_1(x)))    # (26, 26, 32)\n",
        "        x = self.BN32_2(F.relu(self.conv32_2(x)))    # (24, 24, 32)\n",
        "        x = self.BN32_3(F.relu(self.pool_1(x)))        # (12, 12, 32)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.BN64_1(F.relu(self.conv64_1(x)))    # (10, 10, 64)\n",
        "        x = self.BN64_2(F.relu(self.conv64_2(x)))    # (8, 8, 64)\n",
        "        x = self.BN64_3(F.relu(self.pool_2(x)))        # (4, 4, 64)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.BN128(F.relu(self.conv128(x)))     # (1, 1, 128)\n",
        "        # Flatten\n",
        "        x = x.view(-1, 1*1*128)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = F.softmax(self.fc(x))\n",
        "\n",
        "        return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k-VBjpjUK_9"
      },
      "source": [
        "#### Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O2Gj9COUK_9"
      },
      "source": [
        "class Net_DO(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_DO, self).__init__()\n",
        "\n",
        "        self.conv32_1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
        "        self.conv32_2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
        "        self.BN32_1 = nn.BatchNorm2d(32)\n",
        "        self.BN32_2 = nn.BatchNorm2d(32)\n",
        "        self.BN32_3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=5, stride=2, padding=2)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "        self.conv64_1 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "        self.conv64_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
        "        self.BN64_1 = nn.BatchNorm2d(64)\n",
        "        self.BN64_2 = nn.BatchNorm2d(64)\n",
        "        self.BN64_3 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv128 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4)\n",
        "        self.BN128 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.fc = nn.Linear(1*1*128, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):                          # (28, 28, 1)\n",
        "        x = self.BN32_1(F.relu(self.conv32_1(x)))    # (26, 26, 32)\n",
        "        x = self.BN32_2(F.relu(self.conv32_2(x)))    # (24, 24, 32)\n",
        "        x = self.BN32_3(F.relu(self.pool(x)))        # (12, 12, 32)\n",
        "\n",
        "        # x = self.dropout(x)\n",
        "\n",
        "        x = self.BN64_1(F.relu(self.conv64_1(x)))    # (10, 10, 64)\n",
        "        x = self.BN64_2(F.relu(self.conv64_2(x)))    # (8, 8, 64)\n",
        "        x = self.BN64_3(F.relu(self.pool(x)))        # (4, 4, 64)\n",
        "\n",
        "        # x = self.dropout(x)\n",
        "\n",
        "        x = self.BN128(F.relu(self.conv128(x)))     # (1, 1, 128)\n",
        "        # Flatten\n",
        "        x = x.view(-1, 1*1*128)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = F.softmax(self.fc(x))\n",
        "\n",
        "        return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Go8mVLKNPVHp"
      },
      "source": [
        "# AlignMNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdfezt0wSP8m"
      },
      "source": [
        "# Change to the correct path containing the alignmnist.npz file - can be downloaded from github (see readmd)\r\n",
        "file = 'drive/MyDrive/alignmnist.npz'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGodDY8SB8vs"
      },
      "source": [
        "alignmnist = np.load(file)\n",
        "x = alignmnist['x']\n",
        "y = alignmnist['y']\n",
        "\n",
        "x1, y1 = x[:60000], y[:60000]\n",
        "x2, y2 = x[60000:120000], y[60000:120000]\n",
        "x3, y3 = x[120000:180000], y[120000:180000]\n",
        "x4, y4 = x[180000:240000], y[180000:240000]\n",
        "x5, y5 = x[240000:300000], y[240000:300000]\n",
        "x6, y6 = x[300000:360000], y[300000:360000]\n",
        "\n",
        "x1 = [transform(foo) for foo in x1]\n",
        "x2 = [transform(foo) for foo in x2]\n",
        "x3 = [transform(foo) for foo in x3]\n",
        "x4 = [transform(foo) for foo in x4]\n",
        "x5 = [transform(foo) for foo in x5]\n",
        "x6 = [transform(foo) for foo in x6]\n",
        "\n",
        "orig_loader = torch.utils.data.DataLoader(list(zip(x1, y1)), **test_kwargs)\n",
        "corrupt_loader1 = torch.utils.data.DataLoader(list(zip(x2, y2)), **test_kwargs)\n",
        "corrupt_loader2 = torch.utils.data.DataLoader(list(zip(x3, y3)), **test_kwargs)\n",
        "corrupt_loader3 = torch.utils.data.DataLoader(list(zip(x4, y4)), **test_kwargs)\n",
        "corrupt_loader4 = torch.utils.data.DataLoader(list(zip(x5, y5)), **test_kwargs)\n",
        "corrupt_loader5 = torch.utils.data.DataLoader(list(zip(x6, y6)), **test_kwargs)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC8obs16kztc"
      },
      "source": [
        "# Train network versions\r\n",
        "\r\n",
        "**Use this section to train the networks yourself (or skip to next for the pre-trained code)**\r\n",
        "\r\n",
        "_In the section after this you will find the code for the pre-trained models, that are downloadable from github_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmAktL6L33Dq"
      },
      "source": [
        "## BatchNorm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AQF9leqFzXH"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "model = Net_BN().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
        "for epoch in range(1, 20 + 1):\n",
        "    train(model, train_loader, optimizer, criterion, epoch)\n",
        "    test(model, test_loader)\n",
        "    scheduler.step()\n",
        "\n",
        "torch.save(model.state_dict(), \"mnist_cnn_bn.pt\")\n",
        "print()\n",
        "print()\n",
        "test(model, orig_loader)\n",
        "test(model, corrupt_loader1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQV28C2KTaiK"
      },
      "source": [
        "## Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwJlME_DTpNL"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "model = Net_DO().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
        "for epoch in range(1, 20 + 1):\n",
        "    train(model, train_loader, optimizer, criterion, epoch)\n",
        "    test(model, test_loader)\n",
        "    scheduler.step()\n",
        "\n",
        "torch.save(model.state_dict(), \"mnist_cnn_do.pt\")\n",
        "\n",
        "print()\n",
        "print()\n",
        "test(model, orig_loader)\n",
        "test(model, corrupt_loader1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVoPB41lXo91"
      },
      "source": [
        "## Average pool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9trFHaZeX5Lu"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "model = Net_avg().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
        "for epoch in range(1, 20 + 1):\n",
        "    train(model, train_loader, optimizer, criterion, epoch)\n",
        "    test(model, test_loader)\n",
        "    scheduler.step()\n",
        "\n",
        "torch.save(model.state_dict(), \"mnist_cnn_avg-1.pt\")\n",
        "print()\n",
        "print()\n",
        "test(model, orig_loader)\n",
        "test(model, corrupt_loader1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG8gZP8wYFqT"
      },
      "source": [
        "## ConvPool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4XGWldHYKET"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "model = Net_pool().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
        "for epoch in range(1, 20 + 1):\n",
        "    train(model, train_loader, optimizer, criterion, epoch)\n",
        "    test(model, test_loader)\n",
        "    scheduler.step()\n",
        "\n",
        "torch.save(model.state_dict(), \"mnist_cnn_pool.pt\")\n",
        "print()\n",
        "print()\n",
        "test(model, orig_loader)\n",
        "test(model, corrupt_loader1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLs7uhnT1Ct7"
      },
      "source": [
        "## StepLR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcMACuDG1Fnu"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "model = Net().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
        "for epoch in range(1, 20 + 1):\n",
        "    train(model, train_loader, optimizer, criterion, epoch)\n",
        "    test(model, test_loader)\n",
        "    #scheduler.step()\n",
        "\n",
        "torch.save(model.state_dict(), \"mnist_cnn_steplr.pt\")\n",
        "print()\n",
        "print()\n",
        "test(model, orig_loader)\n",
        "test(model, corrupt_loader1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-Z8ZhVdxaxQ"
      },
      "source": [
        "# Pre-trained\r\n",
        "\r\n",
        "**In order to use this, download the nets folder from github and upload to the current runtime. It contains the pre-trained networks**\r\n",
        "\r\n",
        "_If the networks are manually trained, using the section above, each network must be put inside a folder named 'nets', for the below code to run_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eibYXWCGwva_"
      },
      "source": [
        "#### Original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6H5HZbUuOTb",
        "outputId": "20389eb6-36a8-4cd3-d392-5fb5c4950165"
      },
      "source": [
        "model = Net().to(device)\n",
        "model.load_state_dict(torch.load('nets/mnist_cnn.pt'))\n",
        "model.eval()\n",
        "test(model, orig_loader)\n",
        "test(model, corrupt_loader1)\n",
        "test(model, corrupt_loader2)\n",
        "test(model, corrupt_loader3)\n",
        "test(model, corrupt_loader4)\n",
        "test(model, corrupt_loader5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 60000 test images: 99.76 %\n",
            "Accuracy of the network on the 60000 test images: 98.73 %\n",
            "Accuracy of the network on the 60000 test images: 98.72 %\n",
            "Accuracy of the network on the 60000 test images: 98.69 %\n",
            "Accuracy of the network on the 60000 test images: 98.76 %\n",
            "Accuracy of the network on the 60000 test images: 98.77 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69sR1kn9wzvG"
      },
      "source": [
        "#### AveragePool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdrcDxmCwunT",
        "outputId": "f169514a-2298-4858-d5f6-4f5d273a57a1"
      },
      "source": [
        "model = Net_avg().to(device)\n",
        "model.load_state_dict(torch.load('nets/mnist_cnn_avg.pt'))\n",
        "model.eval()\n",
        "\n",
        "test(model, orig_loader)\n",
        "test(model, corrupt_loader1)\n",
        "test(model, corrupt_loader2)\n",
        "test(model, corrupt_loader3)\n",
        "test(model, corrupt_loader4)\n",
        "test(model, corrupt_loader5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 60000 test images: 99.70 %\n",
            "Accuracy of the network on the 60000 test images: 98.45 %\n",
            "Accuracy of the network on the 60000 test images: 98.44 %\n",
            "Accuracy of the network on the 60000 test images: 98.39 %\n",
            "Accuracy of the network on the 60000 test images: 98.45 %\n",
            "Accuracy of the network on the 60000 test images: 98.43 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH8RCqlZw1PQ"
      },
      "source": [
        "#### BatchNorm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDsK4-DP1zqP",
        "outputId": "b77842ed-6094-4c5c-b067-d53fa8f72ff9"
      },
      "source": [
        "model = Net_BN().to(device)\n",
        "model.load_state_dict(torch.load('nets/mnist_cnn_bn.pt'))\n",
        "model.eval()\n",
        "\n",
        "test(model, orig_loader)\n",
        "test(model, corrupt_loader1)\n",
        "test(model, corrupt_loader2)\n",
        "test(model, corrupt_loader3)\n",
        "test(model, corrupt_loader4)\n",
        "test(model, corrupt_loader5)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 60000 test images: 99.25 %\n",
            "Accuracy of the network on the 60000 test images: 98.03 %\n",
            "Accuracy of the network on the 60000 test images: 97.96 %\n",
            "Accuracy of the network on the 60000 test images: 97.98 %\n",
            "Accuracy of the network on the 60000 test images: 98.02 %\n",
            "Accuracy of the network on the 60000 test images: 97.91 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5apVDk27mHo"
      },
      "source": [
        "#### StepLR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qt1rCiKd7kOj",
        "outputId": "6dc88f79-1e0e-4a74-d115-25e19945c3fc"
      },
      "source": [
        "model = Net().to(device)\n",
        "model.load_state_dict(torch.load('nets/mnist_cnn_steplr.pt'))\n",
        "model.eval()\n",
        "\n",
        "test(model, orig_loader)\n",
        "test(model, corrupt_loader1)\n",
        "test(model, corrupt_loader2)\n",
        "test(model, corrupt_loader3)\n",
        "test(model, corrupt_loader4)\n",
        "test(model, corrupt_loader5)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 60000 test images: 99.71 %\n",
            "Accuracy of the network on the 60000 test images: 98.58 %\n",
            "Accuracy of the network on the 60000 test images: 98.66 %\n",
            "Accuracy of the network on the 60000 test images: 98.58 %\n",
            "Accuracy of the network on the 60000 test images: 98.64 %\n",
            "Accuracy of the network on the 60000 test images: 98.57 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y_0gcm29byH"
      },
      "source": [
        "#### ConvPool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhetK6vZ9dn-",
        "outputId": "847b0030-3134-47d6-e014-8ac69a74aed8"
      },
      "source": [
        "model = Net_ConvPool().to(device)\n",
        "model.load_state_dict(torch.load('nets/mnist_cnn_pool.pt'))\n",
        "model.eval()\n",
        "\n",
        "test(model, orig_loader)\n",
        "test(model, corrupt_loader1)\n",
        "test(model, corrupt_loader2)\n",
        "test(model, corrupt_loader3)\n",
        "test(model, corrupt_loader4)\n",
        "test(model, corrupt_loader5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 60000 test images: 99.78 %\n",
            "Accuracy of the network on the 60000 test images: 98.29 %\n",
            "Accuracy of the network on the 60000 test images: 98.21 %\n",
            "Accuracy of the network on the 60000 test images: 98.26 %\n",
            "Accuracy of the network on the 60000 test images: 98.29 %\n",
            "Accuracy of the network on the 60000 test images: 98.23 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byH3dS-v5pT-"
      },
      "source": [
        "#### Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IobLRQLv5rMu",
        "outputId": "8a5b3569-f6b1-45b2-b9b2-fcceb74ced7e"
      },
      "source": [
        "model = Net_DO().to(device)\n",
        "model.load_state_dict(torch.load('nets/mnist_cnn_do.pt'))\n",
        "model.eval()\n",
        "\n",
        "test(model, orig_loader)\n",
        "test(model, corrupt_loader1)\n",
        "test(model, corrupt_loader2)\n",
        "test(model, corrupt_loader3)\n",
        "test(model, corrupt_loader4)\n",
        "test(model, corrupt_loader5)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 60000 test images: 99.88 %\n",
            "Accuracy of the network on the 60000 test images: 98.57 %\n",
            "Accuracy of the network on the 60000 test images: 98.54 %\n",
            "Accuracy of the network on the 60000 test images: 98.58 %\n",
            "Accuracy of the network on the 60000 test images: 98.61 %\n",
            "Accuracy of the network on the 60000 test images: 98.53 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}